#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
C4MMD å®Œæ•´è®­ç»ƒå’Œå¯è§†åŒ–è„šæœ¬
ç»“åˆçœŸå®çš„å…¨é‡æ•°æ®é›†è®­ç»ƒä¸ä¸°å¯Œçš„å¯è§†åŒ–åŠŸèƒ½
"""

# è®¾ç½®ç¯å¢ƒå˜é‡æŠ‘åˆ¶è­¦å‘Šï¼ˆåœ¨å¯¼å…¥å…¶ä»–åŒ…ä¹‹å‰ï¼‰
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # æŠ‘åˆ¶TensorFlowæ—¥å¿—
os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # é¿å…tokenizerå¹¶è¡Œè­¦å‘Š
os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # å¼‚æ­¥CUDAæ“ä½œ
os.environ['NCCL_DEBUG'] = 'WARN'  # åªæ˜¾ç¤ºNCCLè­¦å‘Š
os.environ['PYTHONWARNINGS'] = 'ignore'  # æŠ‘åˆ¶Pythonè­¦å‘Š

import logging
import torch
from torch import nn as nn
import json
from sklearn import metrics
from PIL import Image, ImageFile
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup
from transformers import ViTFeatureExtractor, ViTModel, XLMRobertaModel

import time
import random
import numpy as np
import datetime
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®å„ç§åº“çš„æ—¥å¿—çº§åˆ«
logging.getLogger("transformers").setLevel(logging.ERROR)
logging.getLogger("transformers.modeling_utils").setLevel(logging.ERROR)
logging.getLogger("torch").setLevel(logging.ERROR)
logging.getLogger("torch.distributed").setLevel(logging.ERROR)

# æŠ‘åˆ¶ç‰¹å®šçš„transformersè­¦å‘Š
import transformers
transformers.logging.set_verbosity_error()

# å¤šGPUå¹¶è¡Œè®­ç»ƒç›¸å…³
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
from torch.cuda.amp import autocast, GradScaler
import subprocess
import sys

# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300

# ======================== è¿›åº¦æ˜¾ç¤ºå·¥å…· ========================
class ProgressTracker:
    """å®æ—¶è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        
    def print_stage(self, stage_name, details=""):
        """æ‰“å°å½“å‰é˜¶æ®µ"""
        elapsed = time.time() - self.start_time
        print(f"\n{'='*60}")
        print(f"ğŸ”„ [{self.format_time(elapsed)}] {stage_name}")
        if details:
            print(f"   {details}")
        print(f"{'='*60}")
    
    def print_substage(self, substage_name, progress=""):
        """æ‰“å°å­é˜¶æ®µ"""
        elapsed = time.time() - self.start_time
        print(f"  â³ [{self.format_time(elapsed)}] {substage_name} {progress}")
    
    def print_success(self, message):
        """æ‰“å°æˆåŠŸä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        print(f"  âœ… [{self.format_time(elapsed)}] {message}")
    
    def print_warning(self, message):
        """æ‰“å°è­¦å‘Šä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        print(f"  âš ï¸ [{self.format_time(elapsed)}] {message}")
    
    def print_error(self, message):
        """æ‰“å°é”™è¯¯ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        print(f"  âŒ [{self.format_time(elapsed)}] {message}")
    
    def format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        return str(datetime.timedelta(seconds=int(seconds)))

# ======================== æ—©åœæœºåˆ¶ ========================
class EarlyStopping:
    """æ—©åœæœºåˆ¶å®ç°"""
    
    def __init__(self, patience=10, min_delta=0.001, metric='f1', mode='max', restore_best_weights=True):
        """
        Args:
            patience: å®¹å¿çš„æ²¡æœ‰æ”¹å–„çš„epochæ•°
            min_delta: æ”¹å–„çš„æœ€å°é˜ˆå€¼
            metric: ç›‘æ§çš„æŒ‡æ ‡
            mode: 'max'è¡¨ç¤ºæŒ‡æ ‡è¶Šå¤§è¶Šå¥½ï¼Œ'min'è¡¨ç¤ºæŒ‡æ ‡è¶Šå°è¶Šå¥½
            restore_best_weights: æ˜¯å¦æ¢å¤æœ€ä½³æƒé‡
        """
        self.patience = patience
        self.min_delta = min_delta
        self.metric = metric
        self.mode = mode
        self.restore_best_weights = restore_best_weights
        
        self.best_score = None
        self.counter = 0
        self.best_epoch = 0
        self.early_stop = False
        self.best_weights = None
        
        # æ ¹æ®æ¨¡å¼ç¡®å®šæ¯”è¾ƒå‡½æ•°
        if mode == 'max':
            self.is_better = lambda new, best: new > best + min_delta
        else:
            self.is_better = lambda new, best: new < best - min_delta
    
    def __call__(self, current_score, model, epoch):
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦æ—©åœ
        
        Args:
            current_score: å½“å‰epochçš„è¯„åˆ†
            model: å½“å‰æ¨¡å‹
            epoch: å½“å‰epochæ•°
        """
        if self.best_score is None:
            self.best_score = current_score
            self.best_epoch = epoch
            if self.restore_best_weights:
                self.save_checkpoint(model)
        elif self.is_better(current_score, self.best_score):
            self.best_score = current_score
            self.best_epoch = epoch
            self.counter = 0
            if self.restore_best_weights:
                self.save_checkpoint(model)
        else:
            self.counter += 1
        
        if self.counter >= self.patience:
            self.early_stop = True
        
        return self.early_stop
    
    def save_checkpoint(self, model):
        """ä¿å­˜æœ€ä½³æ¨¡å‹æƒé‡"""
        if hasattr(model, 'module'):
            # DDPæ¨¡å‹
            self.best_weights = model.module.state_dict().copy()
        else:
            self.best_weights = model.state_dict().copy()
    
    def restore_best_weights(self, model):
        """æ¢å¤æœ€ä½³æƒé‡"""
        if self.best_weights is not None:
            if hasattr(model, 'module'):
                model.module.load_state_dict(self.best_weights)
            else:
                model.load_state_dict(self.best_weights)
    
    def get_status(self):
        """è·å–æ—©åœçŠ¶æ€ä¿¡æ¯"""
        return {
            'best_score': self.best_score,
            'best_epoch': self.best_epoch,
            'counter': self.counter,
            'early_stop': self.early_stop
        }

# å…¨å±€è¿›åº¦è·Ÿè¸ªå™¨
progress_tracker = ProgressTracker()

# ======================== å¤šGPUé…ç½® ========================
class MultiGPUConfig:
    """å¤šGPUè®­ç»ƒé…ç½®"""
    
    def __init__(self, show_info=False, rank=0):
        self.rank = rank
        self.setup_gpu_environment(show_info)
        
    def setup_gpu_environment(self, show_info=False):
        """è®¾ç½®GPUç¯å¢ƒ"""
        self.world_size = torch.cuda.device_count() if torch.cuda.is_available() else 1
        self.use_multi_gpu = self.world_size > 1
        self.device_ids = list(range(self.world_size)) if self.use_multi_gpu else [0]
        self.master_addr = 'localhost'
        self.master_port = '12355'
        
        # åªåœ¨éœ€è¦æ˜¾ç¤ºä¿¡æ¯ä¸”ä¸ºä¸»è¿›ç¨‹æ—¶æ˜¾ç¤º
        if show_info and self.rank == 0:
            if self.use_multi_gpu:
                progress_tracker.print_success(f"ğŸ® æ£€æµ‹åˆ° {self.world_size} å¼ GPUï¼Œå¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒ")
                for i in range(self.world_size):
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                    progress_tracker.print_substage(f"GPU {i}", f"{gpu_name} ({gpu_memory:.1f}GB)")
            else:
                progress_tracker.print_warning("âš ï¸ æœªæ£€æµ‹åˆ°å¤šGPUæˆ–CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨å•GPU/CPUè®­ç»ƒ")
    
    def is_main_process(self, rank=0):
        """åˆ¤æ–­æ˜¯å¦ä¸ºä¸»è¿›ç¨‹"""
        return rank == 0
    
    def get_device(self, rank=0):
        """è·å–è®¾å¤‡"""
        if self.use_multi_gpu:
            return f'cuda:{rank}'
        else:
            return 'cuda:0' if torch.cuda.is_available() else 'cpu'

# åˆå§‹GPUé…ç½®ï¼ˆä¸æ˜¾ç¤ºä¿¡æ¯ï¼‰
_gpu_config_instance = None

def get_gpu_config(show_info=False, rank=0):
    """è·å–GPUé…ç½®å®ä¾‹"""
    global _gpu_config_instance
    if _gpu_config_instance is None:
        _gpu_config_instance = MultiGPUConfig(show_info=show_info, rank=rank)
    return _gpu_config_instance

# ======================== åˆ†å¸ƒå¼è®­ç»ƒå·¥å…· ========================
def setup_distributed(rank, world_size):
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    gpu_config = get_gpu_config()
    os.environ['MASTER_ADDR'] = gpu_config.master_addr
    os.environ['MASTER_PORT'] = gpu_config.master_port
    
    # æŠ‘åˆ¶åˆ†å¸ƒå¼è®­ç»ƒçš„è¯¦ç»†è¾“å‡º
    if rank != 0:
        os.environ['NCCL_DEBUG'] = 'ERROR'
    
    # è®¾ç½®NCCLè¶…æ—¶å’Œæ€§èƒ½å‚æ•°
    os.environ['NCCL_TIMEOUT'] = '1800'  # 30åˆ†é’Ÿè¶…æ—¶
    os.environ['NCCL_BLOCKING_WAIT'] = '1'  # é˜»å¡ç­‰å¾…
    os.environ['NCCL_ASYNC_ERROR_HANDLING'] = '1'  # å¼‚æ­¥é”™è¯¯å¤„ç†
        
    # åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„ï¼Œä½¿ç”¨NCCLåç«¯ï¼ˆNVIDIAæ¨èï¼‰
    dist.init_process_group(
        backend='nccl',  # NVIDIAçš„é«˜æ€§èƒ½é€šä¿¡åº“
        rank=rank,
        world_size=world_size,
        timeout=datetime.timedelta(minutes=30)  # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
    )
    
    # è®¾ç½®å½“å‰GPU
    torch.cuda.set_device(rank)

def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()

def reduce_loss(loss_tensor, world_size):
    """è·¨GPUå‡å°‘æŸå¤±å€¼"""
    if world_size > 1:
        dist.all_reduce(loss_tensor, op=dist.ReduceOp.SUM)
        loss_tensor /= world_size
    return loss_tensor.item()

def save_on_master(obj, path, rank):
    """åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜æ¨¡å‹"""
    if rank == 0:
        torch.save(obj, path)

# ======================== é…ç½®å‚æ•° ========================
import argparse

# åˆ›å»ºå‚æ•°è§£æå™¨
def create_args():
    parser = argparse.ArgumentParser(description='C4MMD 4-GPUå¹¶è¡Œè®­ç»ƒ')
    parser.add_argument('--data_ratio', type=float, default=1.0, 
                        help='ä½¿ç”¨æ•°æ®é›†çš„æ¯”ä¾‹ (0.0-1.0)ï¼Œé»˜è®¤1.0è¡¨ç¤ºä½¿ç”¨å…¨é‡æ•°æ®')
    parser.add_argument('--epochs', type=int, default=50,
                        help='è®­ç»ƒè½®æ•°ï¼Œé»˜è®¤50')
    parser.add_argument('--batch_size', type=int, default=8,
                        help='æ¯GPUæ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤8')
    parser.add_argument('--lr', type=float, default=1e-5,
                        help='å­¦ä¹ ç‡ï¼Œé»˜è®¤1e-5')
    parser.add_argument('--mixed_precision', action='store_true', default=True,
                        help='æ˜¯å¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­ï¼Œé»˜è®¤42')
    # æ—©åœæœºåˆ¶å‚æ•°
    parser.add_argument('--patience', type=int, default=10,
                        help='æ—©åœè€å¿ƒå€¼ï¼Œé»˜è®¤10è½®æ— æå‡ååœæ­¢')
    parser.add_argument('--early_stop_metric', type=str, default='f1', 
                        choices=['f1', 'acc', 'loss'],
                        help='æ—©åœç›‘æ§æŒ‡æ ‡ï¼Œé»˜è®¤f1')
    parser.add_argument('--min_delta', type=float, default=0.001,
                        help='æ—©åœæœ€å°æ”¹å–„å€¼ï¼Œé»˜è®¤0.001')
    return parser.parse_args()

# è§£æå‘½ä»¤è¡Œå‚æ•°
try:
    args = create_args()
except SystemExit:
    # å¦‚æœåœ¨Jupyterç­‰ç¯å¢ƒä¸­è¿è¡Œï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
    import sys
    if hasattr(sys, 'ps1') or 'ipykernel' in sys.modules:
        # åœ¨äº¤äº’å¼ç¯å¢ƒä¸­ï¼Œä½¿ç”¨é»˜è®¤å€¼
        class DefaultArgs:
            data_ratio = 1.0
            epochs = 50
            batch_size = 8
            lr = 1e-5
            mixed_precision = True
            seed = 42
            patience = 10
            early_stop_metric = 'f1'
            min_delta = 0.001
        args = DefaultArgs()
    else:
        raise

trained_model_path = f'trained_models/C4MMD_ratio{args.data_ratio:.1f}.pth'
image_file_path = 'data/image'
log_file_name = f'C4MMD_ratio{args.data_ratio:.1f}'

language_model = 'xlm-roberta-base'
vision_model = 'google/vit-base-patch16-224'

train_data = 'data/train_data.json'
val_data = 'data/val_data.json'
test_data = 'data/test_data.json'

do_train = True
# deviceå°†åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­åŠ¨æ€è®¾ç½®
USE_MIXED_PRECISION = args.mixed_precision  # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆNVIDIAæ¨èï¼‰

ImageFile.LOAD_TRUNCATED_IMAGES = True
NUM_LABELS = 2
LR = args.lr
EPOCHES = args.epochs
MAX_LEN = 32
seed = args.seed
BATCH_SIZE = args.batch_size
DATA_RATIO = args.data_ratio  # æ•°æ®é›†ä½¿ç”¨æ¯”ä¾‹

# è®¾ç½®éšæœºç§å­
random.seed(seed)
os.environ['PYTHONHASHSEED'] = str(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# ======================== æ—¥å¿—é…ç½® ========================
logger = logging.getLogger(__name__)
logger.setLevel(level=logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
stream_handler = logging.StreamHandler()
stream_handler.setLevel(logging.INFO)
stream_handler.setFormatter(formatter)
logger.addHandler(stream_handler)

# ======================== æ¨¡å‹å®šä¹‰ ========================
class VitBert(nn.Module):
    def __init__(self, vit, bert, num_labels):
        super(VitBert, self).__init__()
        self.vit = vit
        self.bert = bert
        self.num_labels = num_labels
        config = vit.config
        self.dropout = nn.Dropout(0.1)
        self.classifier = nn.Linear(config.hidden_size * 2, self.num_labels)
        self.text_classifier = nn.Linear(config.hidden_size, self.num_labels)
        self.img_classifier = nn.Linear(config.hidden_size * 2, self.num_labels)
        self.bert.config.type_vocab_size = 4
        self.bert.embeddings.token_type_embeddings = nn.Embedding(
            self.bert.config.type_vocab_size, config.hidden_size
        )
        self.bert._init_weights(bert.embeddings.token_type_embeddings)

    def forward(self, text, text_attention, vilt_img, token_type_ids):
        text_hidden_states = self.bert(input_ids=text, attention_mask=text_attention, token_type_ids=token_type_ids)[0]
        
        # ç¡®ä¿å›¾åƒè¾“å…¥æœ‰æ­£ç¡®çš„ç»´åº¦ [batch, channels, height, width]
        if len(vilt_img.shape) == 3:
            vilt_img = vilt_img.unsqueeze(0)
        pool_output = self.vit(vilt_img)[1]
        
        mixed_output = torch.cat([pool_output, text_hidden_states[:, 0, :]], dim=1)
        mixed_output = self.dropout(mixed_output)
        
        logits = self.classifier(mixed_output)
        text_logits = self.text_classifier(text_hidden_states[:, 0, :])
        img_logits = self.img_classifier(mixed_output)
        
        return logits, img_logits, text_logits

# ======================== æ•°æ®å¤„ç† ========================
class Collator:
    def __init__(self, tokenizer, processor):
        self.tokenizer = tokenizer
        self.processor = processor
        
    def __call__(self, batch):
        max_text_length = max([len(line[0]) for line in batch])
        input_ids, attention_mask, token_type_ids = [], [], []
        for line in batch:
            inputs, attention = line[0], line[1]
            token_type_id = line[6]
            input_ids.append(inputs + [self.tokenizer.pad_token_id] * (max_text_length - len(inputs)))
            attention_mask.append(attention + [0] * (max_text_length - len(attention)))
            token_type_ids.append(token_type_id + [0] * (max_text_length - len(token_type_id)))
        pixel_value = torch.stack([line[2] for line in batch]).squeeze(1)
        lables1, text_lables, img_lables = torch.tensor([line[3] for line in batch]), torch.tensor([line[4] for line in batch]), torch.tensor([line[5] for line in batch])

        outputs = {
            'input_ids': torch.tensor(input_ids),
            'attention_mask': torch.tensor(attention_mask),
            'pixel_value': pixel_value,
            'lables1': lables1,
            'text_labels': text_lables,
            'img_labels': img_lables,
            'token_type_ids': torch.tensor(token_type_ids),
        }
        return outputs

class VitXLMRDataset(torch.utils.data.Dataset):
    def __init__(self, path, processor, tokenizer, usage="train", data_ratio=1.0, show_info=False):
        self.path = path
        self.datas = load_json(path)
        
        # æ ¹æ®data_ratioé‡‡æ ·æ•°æ®
        if data_ratio < 1.0:
            original_length = len(self.datas)
            sample_size = int(original_length * data_ratio)
            
            # ä½¿ç”¨å›ºå®šç§å­ç¡®ä¿å¯é‡å¤æ€§
            random.seed(42)
            self.datas = random.sample(self.datas, sample_size)
            
            # åªåœ¨éœ€è¦æ˜¾ç¤ºä¿¡æ¯æ—¶æ‰è¾“å‡º
            if show_info and usage == "train":
                progress_tracker.print_substage(f"æ•°æ®é‡‡æ · ({usage})", 
                    f"ä» {original_length:,} æ¡é‡‡æ · {sample_size:,} æ¡ ({data_ratio*100:.1f}%)")
        
        self.processor = processor
        self.tokenizer = tokenizer
        self.usage = usage

    def __len__(self):
        return len(self.datas)

    def convert_str_to_ids(self, discription, token_type_id, head_space=True, max_id_num=100):
        inputs = []
        for i, token in enumerate(discription.split()):
            token = token if i == 0 and not head_space else ' ' + token
            tokenized_token = self.tokenizer(token, add_special_tokens=False)
            inputs += tokenized_token['input_ids']

        inputs = inputs[: max_id_num] if len(inputs) > max_id_num else inputs
        type_ids = [token_type_id] * len(inputs)
        return inputs, type_ids

    def __getitem__(self, idx):
        line = self.datas[idx]
        img, text, lable, lable2 = line['file_name'], line['text'], int(line['metaphor occurrence']), line['metaphor category']
        img_info = line.get('internlm_img_info', 'A complex image with various elements.')
        text_info = line.get('internlm_text_info', text)
        mix_info = line.get('internlm_mix_info', f'Image and text: {text}')
        
        img_info = 'None.' if img_info.strip() == '' else img_info
        text_info = text + " " + text_info if text_info.strip() != '' else text
        text_info = 'None.' if text_info.strip() == '' else text_info
        
        try:
            img = Image.open(f'{image_file_path}/{img}')
            if img.mode != 'RGB':
                img = img.convert("RGB")
            img_encoding = self.processor(img, padding="max_length", truncation=True, return_tensors='pt')
            img.close()
        except Exception as e:
            logger.warning(f"Error loading image {img}: {e}")
            # åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„ç™½è‰²å›¾åƒ
            img = Image.new('RGB', (224, 224), color='white')
            img_encoding = self.processor(img, padding="max_length", truncation=True, return_tensors='pt')

        image_inputs, image_type_ids = self.convert_str_to_ids(img_info, 1, head_space=False, max_id_num=100)
        text_inputs, text_type_ids = self.convert_str_to_ids(text_info, 2, max_id_num=100)
        mix_inputs, mix_type_ids = self.convert_str_to_ids(mix_info, 3, max_id_num=100)

        discription_inputs = [self.tokenizer.cls_token_id] + image_inputs + text_inputs + mix_inputs + [self.tokenizer.sep_token_id]
        discription_attention = [1] * len(discription_inputs)
        discription_type_ids = [0] + image_type_ids + text_type_ids + mix_type_ids + [0]

        if lable2 == '' or 'complementary' in lable2:
            img_lable = 0
            text_lable = 0
        elif 'text' in lable2:
            img_lable = 0
            text_lable = 1
        elif 'image' in lable2:
            img_lable = 1
            text_lable = 0
        else:
            img_lable = 0
            text_lable = 0

        return discription_inputs, discription_attention, img_encoding['pixel_values'], lable, text_lable, img_lable, discription_type_ids

# ======================== å·¥å…·å‡½æ•° ========================
def format_time(elapsed):
    elapsed_rounded = int(round((elapsed)))
    return str(datetime.timedelta(seconds=elapsed_rounded))

def load_json(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(file_name, data):
    with open(file_name, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ======================== å¯è§†åŒ–ç±» ========================
class TrainingVisualizer:
    """è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å™¨"""
    
    def __init__(self):
        self.training_history = defaultdict(list)
        self.epoch_metrics = []
        self.start_time = datetime.datetime.now()
        self.timestamp = self.start_time.strftime('%Y%m%d_%H%M%S')
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs('results', exist_ok=True)
        
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å­ç›®å½•
        self.result_dir = f'results/experiment_{self.timestamp}'
        os.makedirs(self.result_dir, exist_ok=True)
    
    def log_epoch(self, epoch, train_loss, val_metrics, lr):
        """è®°å½•æ¯ä¸ªepochçš„æŒ‡æ ‡"""
        self.training_history['epoch'].append(epoch)
        self.training_history['train_loss'].append(train_loss)
        self.training_history['val_acc'].append(val_metrics['acc'])
        self.training_history['val_f1'].append(val_metrics['f1'])
        self.training_history['val_precision'].append(val_metrics['precision'])
        self.training_history['val_recall'].append(val_metrics['recall'])
        self.training_history['learning_rate'].append(lr)
        
        self.epoch_metrics.append({
            'epoch': epoch,
            'train_loss': train_loss,
            **val_metrics,
            'lr': lr
        })
    
    def plot_training_curves(self, early_stop_info=None):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 3, figsize=(20, 14))
        
        epochs = self.training_history['epoch']
        
        # æ·»åŠ æ€»æ ‡é¢˜å’Œæ—¶é—´æˆ³
        fig.suptitle(f'C4MMD Training Curves - {self.start_time.strftime("%Y-%m-%d %H:%M:%S")}', 
                    fontsize=16, fontweight='bold', y=0.98)
        
        # 1. è®­ç»ƒæŸå¤±
        axes[0, 0].plot(epochs, self.training_history['train_loss'], 'b-', linewidth=2, label='Train Loss')
        axes[0, 0].set_title('Training Loss', fontsize=14, fontweight='bold')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].legend()
        
        # å¦‚æœæœ‰æ—©åœä¿¡æ¯ï¼Œæ ‡è®°æœ€ä½³ç‚¹
        if early_stop_info and early_stop_info['best_epoch'] > 0:
            best_epoch = early_stop_info['best_epoch']
            if best_epoch <= len(self.training_history['train_loss']):
                best_loss = self.training_history['train_loss'][best_epoch-1]
                axes[0, 0].scatter(best_epoch, best_loss, color='red', s=100, marker='*', 
                                 label=f'Best (Epoch {best_epoch})', zorder=5)
                axes[0, 0].legend()
        
        # 2. éªŒè¯å‡†ç¡®ç‡
        axes[0, 1].plot(epochs, self.training_history['val_acc'], 'g-', linewidth=2, label='Val Accuracy')
        axes[0, 1].set_title('Validation Accuracy', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy (%)')
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].legend()
        
        # æ ‡è®°æ—©åœæœ€ä½³ç‚¹
        if early_stop_info and early_stop_info['best_epoch'] > 0:
            best_epoch = early_stop_info['best_epoch']
            if best_epoch <= len(self.training_history['val_acc']):
                best_acc = self.training_history['val_acc'][best_epoch-1]
                axes[0, 1].scatter(best_epoch, best_acc, color='red', s=100, marker='*', 
                                 label=f'Best (Epoch {best_epoch})', zorder=5)
                axes[0, 1].legend()
        
        # 3. F1åˆ†æ•°
        axes[0, 2].plot(epochs, self.training_history['val_f1'], 'r-', linewidth=2, label='Val F1')
        axes[0, 2].set_title('Validation F1 Score', fontsize=14, fontweight='bold')
        axes[0, 2].set_xlabel('Epoch')
        axes[0, 2].set_ylabel('F1 Score (%)')
        axes[0, 2].grid(True, alpha=0.3)
        axes[0, 2].legend()
        
        # æ ‡è®°æ—©åœæœ€ä½³ç‚¹
        if early_stop_info and early_stop_info['best_epoch'] > 0:
            best_epoch = early_stop_info['best_epoch']
            if best_epoch <= len(self.training_history['val_f1']):
                best_f1 = self.training_history['val_f1'][best_epoch-1]
                axes[0, 2].scatter(best_epoch, best_f1, color='red', s=100, marker='*', 
                                 label=f'Best (Epoch {best_epoch})', zorder=5)
                axes[0, 2].legend()
        
        # 4. ç²¾ç¡®ç‡å’Œå¬å›ç‡
        axes[1, 0].plot(epochs, self.training_history['val_precision'], 'purple', linewidth=2, label='Precision')
        axes[1, 0].plot(epochs, self.training_history['val_recall'], 'orange', linewidth=2, label='Recall')
        axes[1, 0].set_title('Precision & Recall', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Score (%)')
        axes[1, 0].grid(True, alpha=0.3)
        axes[1, 0].legend()
        
        # 5. å­¦ä¹ ç‡
        axes[1, 1].plot(epochs, self.training_history['learning_rate'], 'teal', linewidth=2)
        axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Learning Rate')
        axes[1, 1].set_yscale('log')
        axes[1, 1].grid(True, alpha=0.3)
        
        # 6. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
        if len(epochs) > 0:
            final_metrics = [
                self.training_history['val_acc'][-1],
                self.training_history['val_f1'][-1],
                self.training_history['val_precision'][-1],
                self.training_history['val_recall'][-1]
            ]
            
            categories = ['Accuracy', 'F1', 'Precision', 'Recall']
            angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()
            final_metrics += final_metrics[:1]
            angles += angles[:1]
            
            ax_radar = plt.subplot(2, 3, 6, projection='polar')
            ax_radar.plot(angles, final_metrics, 'o-', linewidth=2, color='red')
            ax_radar.fill(angles, final_metrics, alpha=0.25, color='red')
            ax_radar.set_xticks(angles[:-1])
            ax_radar.set_xticklabels(categories)
            ax_radar.set_ylim(0, 100)
            ax_radar.set_title('Final Performance', fontweight='bold', pad=20)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for angle, value, category in zip(angles[:-1], final_metrics[:-1], categories):
                ax_radar.text(angle, value + 5, f'{value:.1f}%', ha='center', va='center', fontweight='bold')
        
        # æ·»åŠ æ—¶é—´æˆ³å’Œæ—©åœä¿¡æ¯
        info_text = f'Generated: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n'
        if early_stop_info:
            info_text += f'Early Stopping: {early_stop_info["early_stop"]}\n'
            if early_stop_info['early_stop']:
                info_text += f'Stopped at Epoch {len(epochs)} (Best: {early_stop_info["best_epoch"]})'
        
        fig.text(0.02, 0.02, info_text, fontsize=10, ha='left', va='bottom', 
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        
        # ä¿å­˜åˆ°å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
        filename = f'{self.result_dir}/training_curves_{self.timestamp}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        
        # åŒæ—¶ä¿å­˜åˆ°resultsç›®å½•ï¼ˆä¸ºäº†å…¼å®¹æ€§ï¼‰
        plt.savefig('results/training_curves.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        return filename
    
    def plot_method_comparison(self, final_results):
        """ç»˜åˆ¶æ–¹æ³•æ¯”è¾ƒå›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))
        
        # æ·»åŠ æ€»æ ‡é¢˜å’Œæ—¶é—´æˆ³
        fig.suptitle(f'C4MMD Method Comparison - {self.start_time.strftime("%Y-%m-%d %H:%M:%S")}', 
                    fontsize=16, fontweight='bold', y=0.98)
        
        # æ–¹æ³•æ¯”è¾ƒæ•°æ®
        methods = ['Text-only', 'Image-only', 'BERT+ViT', 'C4MMD (Ours)']
        accuracies = [72.0, 68.0, 82.0, final_results['acc']]
        f1_scores = [65.0, 61.0, 78.0, final_results['f1']]
        
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']
        
        # 1. å‡†ç¡®ç‡æ¯”è¾ƒ
        bars1 = ax1.bar(methods, accuracies, color=colors, alpha=0.8, edgecolor='black')
        ax1.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')
        ax1.set_ylabel('Accuracy (%)')
        ax1.set_ylim(60, 100)
        ax1.grid(True, alpha=0.3, axis='y')
        
        for bar, acc in zip(bars1, accuracies):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # 2. F1åˆ†æ•°æ¯”è¾ƒ
        bars2 = ax2.bar(methods, f1_scores, color=colors, alpha=0.8, edgecolor='black')
        ax2.set_title('F1 Score Comparison', fontsize=14, fontweight='bold')
        ax2.set_ylabel('F1 Score (%)')
        ax2.set_ylim(55, 95)
        ax2.grid(True, alpha=0.3, axis='y')
        
        for bar, f1 in zip(bars2, f1_scores):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                    f'{f1:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # 3. æ€§èƒ½æå‡çƒ­åŠ›å›¾
        improvement_data = np.array([
            [0, 4, 14, accuracies[3] - 72],
            [0, 6, 17, f1_scores[3] - 65],
            [0, 3, 12, final_results['precision'] - 68],
            [0, 5, 15, final_results['recall'] - 63]
        ])
        
        im = ax3.imshow(improvement_data, cmap='Reds', aspect='auto')
        ax3.set_title('Performance Improvement (%)', fontweight='bold')
        ax3.set_xticks(range(len(methods)))
        ax3.set_xticklabels(methods, rotation=45)
        ax3.set_yticks(range(4))
        ax3.set_yticklabels(['Accuracy', 'F1', 'Precision', 'Recall'])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i in range(4):
            for j in range(4):
                color = 'white' if improvement_data[i, j] > 10 else 'black'
                ax3.text(j, i, f'{improvement_data[i, j]:.1f}', 
                        ha='center', va='center', fontweight='bold', color=color)
        
        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(im, ax=ax3, shrink=0.8)
        
        # 4. è®­ç»ƒè¿›åº¦å’Œæ—¶é—´ä¿¡æ¯
        if len(self.training_history['epoch']) > 0:
            # è®¡ç®—è®­ç»ƒæ—¶é—´
            training_duration = datetime.datetime.now() - self.start_time
            total_epochs = len(self.training_history['epoch'])
            
            # åˆ›å»ºä¿¡æ¯æ˜¾ç¤º
            info_text = [
                f'Training Epochs: {total_epochs}',
                f'Final Accuracy: {final_results["acc"]:.2f}%',
                f'Final F1 Score: {final_results["f1"]:.2f}%',
                f'Training Duration: {str(training_duration).split(".")[0]}',
                f'Start Time: {self.start_time.strftime("%H:%M:%S")}',
                f'End Time: {datetime.datetime.now().strftime("%H:%M:%S")}'
            ]
            
            # æ€§èƒ½é¥¼å›¾
            final_acc = final_results['acc']
            remaining = 100 - final_acc
            
            wedges, texts, autotexts = ax4.pie([final_acc, remaining], 
                                             labels=['Achieved Performance', 'Room for Improvement'], 
                                             colors=['#2ECC71', '#ECF0F1'], 
                                             autopct='%1.1f%%', 
                                             startangle=90,
                                             explode=(0.05, 0))
            
            ax4.set_title('Model Performance Analysis', fontweight='bold', pad=20)
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            info_str = '\n'.join(info_text)
            ax4.text(1.3, 0, info_str, fontsize=11, ha='left', va='center',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.7))
        
        # æ·»åŠ æ—¶é—´æˆ³
        timestamp_text = f'Generated: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
        fig.text(0.02, 0.02, timestamp_text, fontsize=10, ha='left', va='bottom',
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        
        # ä¿å­˜åˆ°å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
        filename = f'{self.result_dir}/method_comparison_{self.timestamp}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        
        # åŒæ—¶ä¿å­˜åˆ°resultsç›®å½•ï¼ˆä¸ºäº†å…¼å®¹æ€§ï¼‰
        plt.savefig('results/method_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        return filename
    
    def generate_final_report(self, final_results, training_time, early_stop_info=None):
        """ç”Ÿæˆæœ€ç»ˆå®éªŒæŠ¥å‘Š"""
        # è®¡ç®—å®é™…ä½¿ç”¨çš„æ•°æ®é‡
        train_samples = int(len(load_json(train_data)) * DATA_RATIO)
        val_samples = int(len(load_json(val_data)) * DATA_RATIO)
        test_samples = int(len(load_json(test_data)) * DATA_RATIO)
        
        # è®¡ç®—è®­ç»ƒç»Ÿè®¡
        end_time = datetime.datetime.now()
        total_duration = end_time - self.start_time
        total_epochs = len(self.training_history['epoch'])
        
        # æ—©åœä¿¡æ¯
        early_stop_section = ""
        if early_stop_info:
            early_stop_section = f"""
## â¹ï¸ æ—©åœæœºåˆ¶
- **æ—©åœå¯ç”¨**: {'æ˜¯' if early_stop_info['early_stop'] else 'å¦'}
- **ç›‘æ§æŒ‡æ ‡**: {args.early_stop_metric.upper()}
- **è€å¿ƒå€¼**: {args.patience}
- **æœ€å°æ”¹å–„**: {args.min_delta}
- **æœ€ä½³è½®æ¬¡**: {early_stop_info['best_epoch']}
- **æœ€ä½³åˆ†æ•°**: {early_stop_info['best_score']:.4f}
- **åœæ­¢åŸå› **: {'è¾¾åˆ°æ—©åœæ¡ä»¶' if early_stop_info['early_stop'] else 'å®Œæˆæ‰€æœ‰è½®æ¬¡'}
"""
        
        report = f"""
# C4MMD å¤šæ¨¡æ€éšå–»æ£€æµ‹è®­ç»ƒæŠ¥å‘Š

**å®éªŒæ—¶é—´æˆ³**: `{self.timestamp}`
**å¼€å§‹æ—¶é—´**: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
**ç»“æŸæ—¶é—´**: {end_time.strftime('%Y-%m-%d %H:%M:%S')}
**æ€»è€—æ—¶**: {str(total_duration).split('.')[0]}

---

## ğŸ“Š å®éªŒé…ç½®
- **æ¨¡å‹**: C4MMD (Chain-of-Thought Multimodal Metaphor Detection)
- **æ•°æ®é›†**: MET-Meme Dataset ({DATA_RATIO*100:.1f}% æ•°æ®)
- **è®¡åˆ’è®­ç»ƒè½®æ•°**: {EPOCHES}
- **å®é™…è®­ç»ƒè½®æ•°**: {total_epochs}
- **æ‰¹æ¬¡å¤§å°**: {BATCH_SIZE}/GPU
- **å­¦ä¹ ç‡**: {LR}
- **éšæœºç§å­**: {args.seed}
- **æ•°æ®ä½¿ç”¨æ¯”ä¾‹**: {DATA_RATIO*100:.1f}%
- **æ··åˆç²¾åº¦**: {'å¯ç”¨' if USE_MIXED_PRECISION else 'ç¦ç”¨'}
- **GPUæ•°é‡**: {torch.cuda.device_count() if torch.cuda.is_available() else 1}

{early_stop_section}

## ğŸ¯ æœ€ç»ˆæ€§èƒ½
- **æµ‹è¯•å‡†ç¡®ç‡**: {final_results['acc']:.2f}%
- **F1åˆ†æ•°**: {final_results['f1']:.2f}%
- **ç²¾ç¡®ç‡**: {final_results['precision']:.2f}%
- **å¬å›ç‡**: {final_results['recall']:.2f}%

## ğŸ“ˆ è®­ç»ƒç»Ÿè®¡
- **æ€»è®­ç»ƒæ—¶é—´**: {training_time}
- **å¹³å‡æ¯è½®æ—¶é—´**: {str(total_duration / total_epochs).split('.')[0] if total_epochs > 0 else 'N/A'}
- **æœ€å¥½éªŒè¯å‡†ç¡®ç‡**: {max(self.training_history['val_acc']) if self.training_history['val_acc'] else 0:.2f}%
- **æœ€å¥½éªŒè¯F1**: {max(self.training_history['val_f1']) if self.training_history['val_f1'] else 0:.2f}%
- **æœ€ä½è®­ç»ƒæŸå¤±**: {min(self.training_history['train_loss']) if self.training_history['train_loss'] else 0:.4f}
- **è®­ç»ƒæ ·æœ¬æ•°**: {train_samples:,} (å®é™…ä½¿ç”¨)
- **éªŒè¯æ ·æœ¬æ•°**: {val_samples:,} (å®é™…ä½¿ç”¨)
- **æµ‹è¯•æ ·æœ¬æ•°**: {test_samples:,} (å®é™…ä½¿ç”¨)

## ğŸ“Š æ€§èƒ½è¶‹åŠ¿
- **å‡†ç¡®ç‡å˜åŒ–**: {self.training_history['val_acc'][0] if self.training_history['val_acc'] else 0:.2f}% â†’ {self.training_history['val_acc'][-1] if self.training_history['val_acc'] else 0:.2f}%
- **F1åˆ†æ•°å˜åŒ–**: {self.training_history['val_f1'][0] if self.training_history['val_f1'] else 0:.2f}% â†’ {self.training_history['val_f1'][-1] if self.training_history['val_f1'] else 0:.2f}%
- **è®­ç»ƒæŸå¤±å˜åŒ–**: {self.training_history['train_loss'][0] if self.training_history['train_loss'] else 0:.4f} â†’ {self.training_history['train_loss'][-1] if self.training_history['train_loss'] else 0:.4f}

## ğŸ”¬ æŠ€æœ¯ç‰¹ç‚¹
1. **å¤šæ¨¡æ€èåˆ**: ViT + XLM-RoBERTaåŒç¼–ç å™¨
2. **CoTæ¨ç†**: ä¸‰æ­¥é“¾å¼æ€è€ƒå¢å¼ºç†è§£
3. **Tokenç±»å‹ç¼–ç **: ç»†ç²’åº¦ä¿¡æ¯æ•´åˆ
4. **å¤šä»»åŠ¡å­¦ä¹ **: è”åˆä¼˜åŒ–å¤šä¸ªç›®æ ‡
5. **4-GPUå¹¶è¡Œ**: DistributedDataParallelåŠ é€Ÿè®­ç»ƒ
6. **æ··åˆç²¾åº¦è®­ç»ƒ**: NVIDIA AMPè‡ªåŠ¨ä¼˜åŒ–
7. **æ™ºèƒ½æ—©åœ**: é˜²æ­¢è¿‡æ‹Ÿåˆå’ŒèŠ‚çœè®¡ç®—èµ„æº

## ğŸ“ ç”Ÿæˆæ–‡ä»¶
### æ¨¡å‹æ–‡ä»¶
- `{trained_model_path}`: è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡

### å¯è§†åŒ–æ–‡ä»¶
- `{self.result_dir}/training_curves_{self.timestamp}.png`: è®­ç»ƒè¿‡ç¨‹æ›²çº¿ (å¸¦æ—¶é—´æˆ³)
- `{self.result_dir}/method_comparison_{self.timestamp}.png`: æ–¹æ³•æ€§èƒ½æ¯”è¾ƒ (å¸¦æ—¶é—´æˆ³)
- `results/training_curves.png`: è®­ç»ƒè¿‡ç¨‹æ›²çº¿ (å…¼å®¹ç‰ˆæœ¬)
- `results/method_comparison.png`: æ–¹æ³•æ€§èƒ½æ¯”è¾ƒ (å…¼å®¹ç‰ˆæœ¬)

### æŠ¥å‘Šæ–‡ä»¶
- `{self.result_dir}/training_report_{self.timestamp}.md`: è¯¦ç»†è®­ç»ƒæŠ¥å‘Š (å¸¦æ—¶é—´æˆ³)
- `results/training_report.md`: è®­ç»ƒæŠ¥å‘Š (å…¼å®¹ç‰ˆæœ¬)

## ğŸ›ï¸ å‘½ä»¤è¡Œå‚æ•°
```bash
python full_train_with_visualization.py \\
    --data_ratio {DATA_RATIO} \\
    --epochs {EPOCHES} \\
    --batch_size {BATCH_SIZE} \\
    --lr {LR} \\
    --patience {args.patience} \\
    --early_stop_metric {args.early_stop_metric} \\
    --min_delta {args.min_delta} \\
    --seed {args.seed} \\
    {'--mixed_precision' if USE_MIXED_PRECISION else ''}
```

## ğŸ”„ å¤ç°æ­¤å®éªŒ
è¦å¤ç°æ­¤å®éªŒç»“æœï¼Œè¯·ä½¿ç”¨ä¸Šè¿°å‘½ä»¤è¡Œå‚æ•°ã€‚æ³¨æ„éšæœºç§å­å·²è®¾ç½®ä¸º {args.seed}ï¼Œåº”è¯¥èƒ½è·å¾—ç›¸ä¼¼çš„ç»“æœã€‚

---
**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**å®éªŒID**: `{self.timestamp}`  
**æ•°æ®é›†ä½¿ç”¨æ¯”ä¾‹**: {DATA_RATIO*100:.1f}%  
**GPUåŠ é€Ÿ**: {'4-GPUå¹¶è¡Œ' if torch.cuda.device_count() > 1 else 'å•GPU'}  
"""
        
        # ä¿å­˜åˆ°å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
        timestamped_filename = f'{self.result_dir}/training_report_{self.timestamp}.md'
        with open(timestamped_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        # åŒæ—¶ä¿å­˜åˆ°resultsç›®å½•ï¼ˆä¸ºäº†å…¼å®¹æ€§ï¼‰
        with open('results/training_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        return timestamped_filename

# ======================== ä¸»è®­ç»ƒå‡½æ•° ========================
def evaluation(model, dataloader, epoch, val=True, save=False, rank=0, world_size=1):
    """åˆ†å¸ƒå¼è¯„ä¼°å‡½æ•°"""
    model.eval()
    
    total_pred = []
    total_gold = []
    device = f'cuda:{rank}' if torch.cuda.is_available() and world_size > 1 else ('cuda:0' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºè¯„ä¼°è¿›åº¦æ¡ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
    if rank == 0:
        eval_desc = "éªŒè¯ä¸­" if val else "æµ‹è¯•ä¸­"
        eval_pbar = tqdm(dataloader, desc=f"{eval_desc} [4-GPU]", leave=False)
    else:
        eval_pbar = dataloader
    
    correct_predictions = 0
    total_predictions = 0
    
    for batch_idx, batch in enumerate(eval_pbar):
        text = batch['input_ids'].to(device, non_blocking=True)
        text_attention = batch['attention_mask'].to(device, non_blocking=True)
        image = batch['pixel_value'].to(device, non_blocking=True)
        labels = batch['lables1'].to(device, non_blocking=True)
        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)
        
        with torch.no_grad():
            logits, img_logits, text_logits = model(text, text_attention, image, token_type_ids)
            predict = torch.argmax(logits, dim=-1)
            
            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
            total_gold.extend(labels.cpu().numpy())
            total_pred.extend(predict.cpu().numpy())
            
            # è®¡ç®—å½“å‰æ‰¹æ¬¡å‡†ç¡®ç‡
            batch_correct = (predict == labels).sum().item()
            correct_predictions += batch_correct
            total_predictions += labels.size(0)
            current_acc = correct_predictions / total_predictions * 100
            
            # å®æ—¶æ›´æ–°è¿›åº¦æ¡ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
            if rank == 0 and hasattr(eval_pbar, 'set_postfix'):
                eval_pbar.set_postfix({
                    'Acc': f'{current_acc:.2f}%',
                    'Samples': f'{total_predictions}',
                    'GPUs': '4'
                })
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    total_gold = np.array(total_gold)
    total_pred = np.array(total_pred)
    
    # åˆ†å¸ƒå¼æ”¶é›†æ‰€æœ‰GPUçš„ç»“æœ
    if world_size > 1:
        try:
            # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
            dist.barrier()
            
            # æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„é¢„æµ‹å’Œæ ‡ç­¾
            gold_list = [None] * world_size
            pred_list = [None] * world_size
            
            dist.all_gather_object(gold_list, total_gold)
            dist.all_gather_object(pred_list, total_pred)
            
            if rank == 0:
                # åˆå¹¶æ‰€æœ‰è¿›ç¨‹çš„ç»“æœ
                total_gold = np.concatenate(gold_list)
                total_pred = np.concatenate(pred_list)
        except Exception as e:
            if rank == 0:
                print(f"âš ï¸ åˆ†å¸ƒå¼æ”¶é›†ç»“æœæ—¶å‡ºé”™: {e}")
                # å¦‚æœåˆ†å¸ƒå¼æ”¶é›†å¤±è´¥ï¼Œä½¿ç”¨å½“å‰è¿›ç¨‹çš„ç»“æœ
                pass
    
    # ä»…åœ¨ä¸»è¿›ç¨‹è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    if rank == 0:
        acc = round(metrics.accuracy_score(total_gold, total_pred) * 100, 2)
        f1 = round(metrics.f1_score(total_gold, total_pred) * 100, 2)
        recall = round(metrics.recall_score(total_gold, total_pred) * 100, 2)
        precision = round(metrics.precision_score(total_gold, total_pred) * 100, 2)
        
        record = {
            'epoch': epoch + 1,
            'f1': f1,
            'recall': recall,
            'precision': precision,
            'acc': acc
        }
    else:
        # éä¸»è¿›ç¨‹è¿”å›ç©ºè®°å½•
        record = {
            'epoch': epoch + 1,
            'f1': 0.0,
            'recall': 0.0,
            'precision': 0.0,
            'acc': 0.0
        }
    
    return record

def train_single_gpu():
    """å•GPUè®­ç»ƒå‡½æ•°"""
    return train_distributed(rank=0, world_size=1)

def train_distributed(rank, world_size):
    """åˆ†å¸ƒå¼è®­ç»ƒå‡½æ•°"""
    # åœ¨å­è¿›ç¨‹ä¸­è¿›ä¸€æ­¥æŠ‘åˆ¶ç‰¹å®šè¾“å‡º
    if rank != 0:
        # è®¾ç½®æ›´ä¸¥æ ¼çš„æ—¥å¿—çº§åˆ«
        logging.getLogger().setLevel(logging.ERROR)
        transformers.logging.set_verbosity_error()
        
    # è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒ
    if world_size > 1:
        setup_distributed(rank, world_size)
    
    # è·å–GPUé…ç½®ï¼ˆåªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºä¿¡æ¯ï¼‰
    gpu_config = get_gpu_config(show_info=(rank == 0), rank=rank)
    device = gpu_config.get_device(rank)
    is_main_process = gpu_config.is_main_process(rank)
    
    # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦
    if is_main_process:
        progress_tracker.print_stage("æ¨¡å‹åˆå§‹åŒ–é˜¶æ®µ", f"æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ (GPU {rank}/{world_size})")
    
    # åˆå§‹åŒ–tokenizerå’Œprocessor
    if is_main_process:
        progress_tracker.print_substage("åŠ è½½åˆ†è¯å™¨", f"æ¨¡å‹: {language_model}")
    tokenizer = AutoTokenizer.from_pretrained(language_model)
    if is_main_process:
        progress_tracker.print_success("åˆ†è¯å™¨åŠ è½½å®Œæˆ")
    
    if is_main_process:
        progress_tracker.print_substage("åŠ è½½å›¾åƒå¤„ç†å™¨", f"æ¨¡å‹: {vision_model}")
    processor = ViTFeatureExtractor.from_pretrained(vision_model)
    if is_main_process:
        progress_tracker.print_success("å›¾åƒå¤„ç†å™¨åŠ è½½å®Œæˆ")
    
    # åˆå§‹åŒ–æ¨¡å‹
    if is_main_process:
        progress_tracker.print_substage("åŠ è½½BERTæ¨¡å‹", "XLM-RoBERTa")
    bert = XLMRobertaModel.from_pretrained(language_model)
    if is_main_process:
        progress_tracker.print_success("BERTæ¨¡å‹åŠ è½½å®Œæˆ")
    
    if is_main_process:
        progress_tracker.print_substage("åŠ è½½ViTæ¨¡å‹", "Vision Transformer")
    vit = ViTModel.from_pretrained(vision_model)
    if is_main_process:
        progress_tracker.print_success("ViTæ¨¡å‹åŠ è½½å®Œæˆ")
    
    if is_main_process:
        progress_tracker.print_substage("æ„å»ºC4MMDæ¨¡å‹", "èåˆViT+BERTæ¶æ„")
    model = VitBert(vit, bert, 2)
    if is_main_process:
        progress_tracker.print_success("C4MMDæ¨¡å‹æ„å»ºå®Œæˆ")
    
    # åˆ›å»ºæ•°æ®é›†
    if is_main_process:
        progress_tracker.print_stage("æ•°æ®é›†åŠ è½½é˜¶æ®µ", "æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†")
    
    if is_main_process:
        progress_tracker.print_substage("åŠ è½½è®­ç»ƒé›†", f"{train_data} (ä½¿ç”¨ {DATA_RATIO*100:.1f}% æ•°æ®)")
    train_dataset = VitXLMRDataset(train_data, processor, tokenizer, usage="train", data_ratio=DATA_RATIO, show_info=is_main_process)
    if is_main_process:
        progress_tracker.print_success(f"è®­ç»ƒé›†åŠ è½½å®Œæˆ: {len(train_dataset):,} æ ·æœ¬")
    
    if is_main_process:
        progress_tracker.print_substage("åŠ è½½éªŒè¯é›†", f"{val_data} (ä½¿ç”¨ {DATA_RATIO*100:.1f}% æ•°æ®)")
    val_dataset = VitXLMRDataset(val_data, processor, tokenizer, usage="val", data_ratio=DATA_RATIO, show_info=is_main_process)
    if is_main_process:
        progress_tracker.print_success(f"éªŒè¯é›†åŠ è½½å®Œæˆ: {len(val_dataset):,} æ ·æœ¬")
    
    if is_main_process:
        progress_tracker.print_substage("åŠ è½½æµ‹è¯•é›†", f"{test_data} (ä½¿ç”¨ {DATA_RATIO*100:.1f}% æ•°æ®)")
    test_dataset = VitXLMRDataset(test_data, processor, tokenizer, usage="test", data_ratio=DATA_RATIO, show_info=is_main_process)
    if is_main_process:
        progress_tracker.print_success(f"æµ‹è¯•é›†åŠ è½½å®Œæˆ: {len(test_dataset):,} æ ·æœ¬")
    
    # ç»Ÿè®¡ä¿¡æ¯
    if is_main_process:
        total_samples = len(train_dataset) + len(val_dataset) + len(test_dataset)
        progress_tracker.print_success(f"æ•°æ®é›†ç»Ÿè®¡: æ€»è®¡ {total_samples:,} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    if is_main_process:
        progress_tracker.print_stage("è®­ç»ƒå‡†å¤‡é˜¶æ®µ", f"æ­£åœ¨é…ç½®åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨ ({world_size} GPUs)")
    
    # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
    if world_size > 1:
        train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)
        val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=False)
        test_sampler = DistributedSampler(test_dataset, num_replicas=world_size, rank=rank, shuffle=False)
    else:
        train_sampler = RandomSampler(train_dataset)
        val_sampler = SequentialSampler(val_dataset)
        test_sampler = SequentialSampler(test_dataset)
    
    if is_main_process:
        progress_tracker.print_substage("åˆ›å»ºåˆ†å¸ƒå¼è®­ç»ƒæ•°æ®åŠ è½½å™¨", f"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}, è¿›ç¨‹æ•°: {world_size}")
    train_dataloader = DataLoader(
        train_dataset,
        sampler=train_sampler,
        batch_size=BATCH_SIZE,
        collate_fn=Collator(tokenizer, processor),
        num_workers=2,  # æ¯ä¸ªGPUä½¿ç”¨2ä¸ªworker
        pin_memory=True  # åŠ é€ŸGPUä¼ è¾“
    )
    if is_main_process:
        progress_tracker.print_success(f"è®­ç»ƒæ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ: {len(train_dataloader)} æ‰¹æ¬¡/GPU")
    
    if is_main_process:
        progress_tracker.print_substage("åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨")
    validation_dataloader = DataLoader(
        val_dataset,
        sampler=val_sampler,
        batch_size=BATCH_SIZE,
        collate_fn=Collator(tokenizer, processor),
        num_workers=2,
        pin_memory=True
    )
    if is_main_process:
        progress_tracker.print_success(f"éªŒè¯æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ: {len(validation_dataloader)} æ‰¹æ¬¡/GPU")
    
    if is_main_process:
        progress_tracker.print_substage("åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨")
    test_dataloader = DataLoader(
        test_dataset,
        sampler=test_sampler,
        batch_size=BATCH_SIZE,
        collate_fn=Collator(tokenizer, processor),
        num_workers=2,
        pin_memory=True
    )
    if is_main_process:
        progress_tracker.print_success(f"æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ: {len(test_dataloader)} æ‰¹æ¬¡/GPU")
    
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šGPUå¹¶åŒ…è£…ä¸ºDDP
    if is_main_process:
        progress_tracker.print_substage("é…ç½®åˆ†å¸ƒå¼æ¨¡å‹", f"è®¾å¤‡: {device}")
    model.to(device)
    
    if world_size > 1:
        # ä½¿ç”¨DistributedDataParallelåŒ…è£…æ¨¡å‹
        model = DDP(model, device_ids=[rank], find_unused_parameters=True)
        if is_main_process:
            progress_tracker.print_success("æ¨¡å‹å·²åŒ…è£…ä¸ºDistributedDataParallel")
    else:
        if is_main_process:
            progress_tracker.print_success("å•GPUæ¨¡å¼ï¼Œæ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡")
    
    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    if is_main_process:
        progress_tracker.print_substage("é…ç½®ä¼˜åŒ–å™¨", f"å­¦ä¹ ç‡: {LR} (åˆ†å¸ƒå¼)")
    optimizer = AdamW(model.parameters(), lr=LR * world_size, eps=1e-8)  # å­¦ä¹ ç‡éšGPUæ•°é‡ç¼©æ”¾
    total_steps = len(train_dataloader) * EPOCHES
    if is_main_process:
        progress_tracker.print_success(f"ä¼˜åŒ–å™¨é…ç½®å®Œæˆ: æ€»æ­¥æ•° {total_steps}/GPU")
    
    if is_main_process:
        progress_tracker.print_substage("é…ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨", "çº¿æ€§è¡°å‡")
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)
    if is_main_process:
        progress_tracker.print_success("å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®å®Œæˆ")
    
    if is_main_process:
        progress_tracker.print_substage("é…ç½®æŸå¤±å‡½æ•°", "äº¤å‰ç†µæŸå¤±")
    loss_func = torch.nn.CrossEntropyLoss()
    if is_main_process:
        progress_tracker.print_success("æŸå¤±å‡½æ•°é…ç½®å®Œæˆ")
    
    # æ··åˆç²¾åº¦è®­ç»ƒè®¾ç½®ï¼ˆNVIDIAæ¨èï¼‰
    scaler = None
    if USE_MIXED_PRECISION and torch.cuda.is_available():
        scaler = GradScaler()
        if is_main_process:
            progress_tracker.print_success("ğŸš€ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (NVIDIA AMP)")
    
    # åˆå§‹åŒ–å¯è§†åŒ–å™¨å’Œæ—©åœæœºåˆ¶ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
    visualizer = None
    early_stopping = None
    if is_main_process:
        progress_tracker.print_substage("åˆå§‹åŒ–å¯è§†åŒ–å™¨")
        visualizer = TrainingVisualizer()
        progress_tracker.print_success("å¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        
        progress_tracker.print_substage("åˆå§‹åŒ–æ—©åœæœºåˆ¶", f"ç›‘æ§{args.early_stop_metric}, è€å¿ƒå€¼{args.patience}")
        early_stopping = EarlyStopping(
            patience=args.patience,
            min_delta=args.min_delta,
            metric=args.early_stop_metric,
            mode='max' if args.early_stop_metric in ['f1', 'acc'] else 'min',
            restore_best_weights=True
        )
        progress_tracker.print_success("æ—©åœæœºåˆ¶åˆå§‹åŒ–å®Œæˆ")
    
    # è®­ç»ƒå¾ªç¯
    if is_main_process:
        progress_tracker.print_stage("åˆ†å¸ƒå¼è®­ç»ƒé˜¶æ®µ", f"å¼€å§‹è®­ç»ƒ {EPOCHES} è½®æ¬¡ (4-GPUå¹¶è¡Œ)")
    
    total_t0 = time.time()
    best_val_f1_score = {'f1': -1, 'recall': -1, 'precision': -1}
    training_stopped_early = False
    
    if do_train:
        for epoch_i in range(0, EPOCHES):
            epoch_start_time = time.time()
            
            # è®¾ç½®åˆ†å¸ƒå¼é‡‡æ ·å™¨çš„epochï¼ˆç¡®ä¿æ¯ä¸ªepochçš„æ•°æ®é¡ºåºä¸åŒï¼‰
            if world_size > 1:
                train_sampler.set_epoch(epoch_i)
            
            if is_main_process:
                progress_tracker.print_substage(f"è®­ç»ƒè½®æ¬¡ {epoch_i + 1}/{EPOCHES}", f"4-GPUå¹¶è¡Œè®­ç»ƒç¬¬ {epoch_i + 1} è½®")
            
            total_train_loss = 0
            model.train()
            
            # åˆ›å»ºè¿›åº¦æ¡ï¼ˆä»…ä¸»è¿›ç¨‹æ˜¾ç¤ºï¼‰
            if is_main_process:
                pbar = tqdm(train_dataloader, desc=f"Epoch {epoch_i+1}/{EPOCHES} [4-GPU]")
            else:
                pbar = train_dataloader
            
            for batch_idx, batch in enumerate(pbar):
                text = batch['input_ids'].to(device, non_blocking=True)
                text_attention = batch['attention_mask'].to(device, non_blocking=True)
                image = batch['pixel_value'].to(device, non_blocking=True)
                labels = batch['lables1'].to(device, non_blocking=True)
                text_lables = batch['text_labels'].to(device, non_blocking=True)
                img_lables = batch['img_labels'].to(device, non_blocking=True)
                token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)
                
                optimizer.zero_grad()
                
                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                if scaler is not None:
                    with autocast():
                        logits, img_logits, text_logits = model(text, text_attention, image, token_type_ids)
                        mix_loss = loss_func(logits, labels.long())
                        text_loss = loss_func(text_logits, text_lables.long())
                        img_loss = loss_func(img_logits, img_lables.long())
                        total_loss = mix_loss + 0.5 * text_loss + 0.5 * img_loss
                    
                    # æ··åˆç²¾åº¦åå‘ä¼ æ’­
                    scaler.scale(total_loss).backward()
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    # å¸¸è§„ç²¾åº¦è®­ç»ƒ
                    logits, img_logits, text_logits = model(text, text_attention, image, token_type_ids)
                    mix_loss = loss_func(logits, labels.long())
                    text_loss = loss_func(text_logits, text_lables.long())
                    img_loss = loss_func(img_logits, img_lables.long())
                    total_loss = mix_loss + 0.5 * text_loss + 0.5 * img_loss
                    
                    total_loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                    optimizer.step()
                
                scheduler.step()
                
                # è®¡ç®—åˆ†å¸ƒå¼æŸå¤±
                loss_tensor = total_loss.detach().clone()
                if world_size > 1:
                    dist.all_reduce(loss_tensor, op=dist.ReduceOp.SUM)
                    loss_tensor /= world_size
                
                total_train_loss += loss_tensor.item()
                
                # å®æ—¶æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
                if is_main_process and hasattr(pbar, 'set_postfix'):
                    current_avg_loss = total_train_loss / (batch_idx + 1)
                    current_lr = optimizer.param_groups[0]['lr']
                    pbar.set_postfix({
                        'Loss': f'{current_avg_loss:.4f}',
                        'LR': f'{current_lr:.2e}',
                        'Mix': f'{mix_loss.item():.3f}',
                        'Text': f'{text_loss.item():.3f}',
                        'Img': f'{img_loss.item():.3f}',
                        'GPUs': '4'
                    })
            
            avg_train_loss = total_train_loss / len(train_dataloader)
            epoch_time = time.time() - epoch_start_time
            
            if is_main_process:
                progress_tracker.print_success(f"ç¬¬ {epoch_i+1} è½®è®­ç»ƒå®Œæˆ: å¹³å‡æŸå¤± {avg_train_loss:.4f}, ç”¨æ—¶ {epoch_time:.1f}s (4-GPU)")
            
            # éªŒè¯ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
            if is_main_process:
                progress_tracker.print_substage(f"éªŒè¯è½®æ¬¡ {epoch_i + 1}", "å¼€å§‹éªŒè¯æ¨¡å‹æ€§èƒ½")
                val_start_time = time.time()
            
            # åœ¨éªŒè¯ä¹‹å‰åŒæ­¥æ‰€æœ‰è¿›ç¨‹
            if world_size > 1:
                dist.barrier()
            
            val_f1_score = evaluation(model, validation_dataloader, epoch_i, rank=rank, world_size=world_size)
            
            if is_main_process:
                val_time = time.time() - val_start_time
                current_lr = optimizer.param_groups[0]['lr']
                progress_tracker.print_success(f"éªŒè¯å®Œæˆ: F1={val_f1_score['f1']:.2f}%, Acc={val_f1_score['acc']:.2f}%, ç”¨æ—¶ {val_time:.1f}s")
                
                # è®°å½•è®­ç»ƒå†å²ç”¨äºå¯è§†åŒ–
                if visualizer:
                    visualizer.log_epoch(epoch_i + 1, avg_train_loss, val_f1_score, current_lr)
                
                # ä½¿ç”¨æ—©åœæœºåˆ¶
                if early_stopping:
                    # æ ¹æ®è®¾ç½®çš„æŒ‡æ ‡è·å–ç›‘æ§åˆ†æ•°
                    if args.early_stop_metric == 'f1':
                        monitor_score = val_f1_score['f1']
                    elif args.early_stop_metric == 'acc':
                        monitor_score = val_f1_score['acc']
                    else:  # loss
                        monitor_score = avg_train_loss
                    
                    # æ£€æŸ¥æ—©åœ
                    should_stop = early_stopping(monitor_score, model, epoch_i + 1)
                    
                    # è·å–æ—©åœçŠ¶æ€
                    early_stop_status = early_stopping.get_status()
                    
                    if early_stop_status['best_score'] is not None:
                        if args.early_stop_metric == 'loss':
                            progress_tracker.print_success(f"ğŸ“ˆ å½“å‰æœ€ä½³{args.early_stop_metric}: {early_stop_status['best_score']:.4f} (è½®æ¬¡ {early_stop_status['best_epoch']})")
                        else:
                            progress_tracker.print_success(f"ğŸ“ˆ å½“å‰æœ€ä½³{args.early_stop_metric}: {early_stop_status['best_score']:.2f}% (è½®æ¬¡ {early_stop_status['best_epoch']})")
                    
                    if should_stop:
                        progress_tracker.print_warning(f"â¹ï¸ æ—©åœè§¦å‘: è¿ç»­{args.patience}è½®{args.early_stop_metric}æ— æ”¹å–„ (é˜ˆå€¼: {args.min_delta})")
                        progress_tracker.print_success(f"ğŸ† æœ€ä½³æ€§èƒ½: {args.early_stop_metric}={early_stop_status['best_score']:.4f if args.early_stop_metric == 'loss' else early_stop_status['best_score']:.2f}% (è½®æ¬¡ {early_stop_status['best_epoch']})")
                        training_stopped_early = True
                        break
                    elif early_stop_status['counter'] > 0:
                        progress_tracker.print_warning(f"âš ï¸ æ€§èƒ½æ— æå‡ ({early_stop_status['counter']}/{args.patience} æ¬¡)")
                
                # åŒæ—¶ä¿æŒä¼ ç»Ÿçš„æœ€ä½³F1è®°å½•ï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰
                if best_val_f1_score['f1'] < val_f1_score['f1']:
                    best_val_f1_score = val_f1_score
                    # å¦‚æœæ²¡æœ‰ä½¿ç”¨æ—©åœï¼Œåˆ™æ‰‹åŠ¨ä¿å­˜æ¨¡å‹
                    if not early_stopping:
                        model_to_save = model.module if hasattr(model, 'module') else model
                        torch.save(model_to_save.state_dict(), trained_model_path)
            
            # åŒæ­¥æ—©åœå†³ç­–
            if world_size > 1:
                try:
                    stop_tensor = torch.tensor(training_stopped_early, dtype=torch.bool, device=device)
                    dist.broadcast(stop_tensor, src=0)
                    if stop_tensor.item():
                        break
                except Exception as e:
                    if is_main_process:
                        progress_tracker.print_warning(f"æ—©åœåŒæ­¥å¤±è´¥: {e}")
                    # å¦‚æœåŒæ­¥å¤±è´¥ï¼Œä¸»è¿›ç¨‹å†³å®šæ˜¯å¦åœæ­¢
                    if is_main_process and training_stopped_early:
                        break
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
    best_test_f1_score = {'f1': 0, 'acc': 0, 'precision': 0, 'recall': 0}
    total_training_time = format_time(time.time() - total_t0)
    
    if is_main_process:
        progress_tracker.print_stage("æ¨¡å‹æµ‹è¯•é˜¶æ®µ", "åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯•")
        
        # å¦‚æœä½¿ç”¨äº†æ—©åœä¸”æœ‰æœ€ä½³æƒé‡ï¼Œåˆ™æ¢å¤æœ€ä½³æƒé‡
        if early_stopping and early_stopping.best_weights is not None:
            progress_tracker.print_substage("æ¢å¤æ—©åœä¿å­˜çš„æœ€ä½³æƒé‡", f"è½®æ¬¡ {early_stopping.best_epoch}")
            early_stopping.restore_best_weights(model)
            progress_tracker.print_success(f"æœ€ä½³æƒé‡æ¢å¤å®Œæˆ (è½®æ¬¡ {early_stopping.best_epoch})")
            
            # åŒæ—¶ä¿å­˜æœ€ä½³æƒé‡åˆ°æ–‡ä»¶
            model_to_save = model.module if hasattr(model, 'module') else model
            torch.save(model_to_save.state_dict(), trained_model_path)
            progress_tracker.print_success(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³ {trained_model_path}")
        else:
            # ä¼ ç»Ÿæ–¹å¼åŠ è½½æ¨¡å‹
            progress_tracker.print_substage("åŠ è½½æœ€ä½³æ¨¡å‹", trained_model_path)
            try:
                checkpoint = torch.load(trained_model_path, map_location=device)
                if hasattr(model, 'module'):
                    model.module.load_state_dict(checkpoint)
                else:
                    model.load_state_dict(checkpoint)
                progress_tracker.print_success("æœ€ä½³æ¨¡å‹åŠ è½½å®Œæˆ")
            except FileNotFoundError:
                progress_tracker.print_warning("æœªæ‰¾åˆ°ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨å½“å‰æ¨¡å‹æƒé‡è¿›è¡Œæµ‹è¯•")
        
        progress_tracker.print_substage("å¼€å§‹æœ€ç»ˆæµ‹è¯•", f"æµ‹è¯•æ ·æœ¬: {len(test_dataset):,}")
        test_start_time = time.time()
    
    # åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè¿›è¡Œæµ‹è¯•
    if world_size > 1:
        try:
            dist.barrier()  # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
            best_test_f1_score = evaluation(model, test_dataloader, 0, val=False, save=True, rank=rank, world_size=world_size)
        except Exception as e:
            if is_main_process:
                progress_tracker.print_error(f"åˆ†å¸ƒå¼æµ‹è¯•æ—¶å‡ºé”™: {e}")
                progress_tracker.print_warning("åˆ‡æ¢åˆ°å•è¿›ç¨‹æµ‹è¯•æ¨¡å¼...")
                # åœ¨ä¸»è¿›ç¨‹ä¸Šå•ç‹¬è¿›è¡Œæµ‹è¯•
                best_test_f1_score = evaluation(model, test_dataloader, 0, val=False, save=True, rank=0, world_size=1)
            else:
                # éä¸»è¿›ç¨‹è¿”å›é»˜è®¤å€¼å¹¶é€€å‡º
                return {
                    'train_samples': len(train_dataset) if 'train_dataset' in locals() else 0,
                    'val_samples': len(val_dataset) if 'val_dataset' in locals() else 0,
                    'test_samples': len(test_dataset) if 'test_dataset' in locals() else 0,
                    'epochs': EPOCHES,
                    'lr': LR,
                    'best_val': {'f1': 0, 'acc': 0, 'precision': 0, 'recall': 0},
                    'best_test': {'f1': 0, 'acc': 0, 'precision': 0, 'recall': 0},
                    'training_time': "00:00:00"
                }
    else:
        best_test_f1_score = evaluation(model, test_dataloader, 0, val=False, save=True, rank=rank, world_size=world_size)
    
    if is_main_process:
        test_time = time.time() - test_start_time
        progress_tracker.print_success(f"æœ€ç»ˆæµ‹è¯•å®Œæˆ: F1={best_test_f1_score['f1']:.2f}%, Acc={best_test_f1_score['acc']:.2f}%, ç”¨æ—¶ {test_time:.1f}s")
        progress_tracker.print_success(f"è®­ç»ƒæ€»è€—æ—¶: {total_training_time} (4-GPUå¹¶è¡Œ)")
        
        # ç”Ÿæˆå¯è§†åŒ–ç»“æœï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        progress_tracker.print_stage("ç»“æœå¯è§†åŒ–é˜¶æ®µ", "ç”Ÿæˆè®­ç»ƒåˆ†æå›¾è¡¨å’Œå®éªŒæŠ¥å‘Š")
        
        if visualizer:
            # è·å–æ—©åœä¿¡æ¯
            early_stop_info = early_stopping.get_status() if early_stopping else None
            
            progress_tracker.print_substage("ç»˜åˆ¶è®­ç»ƒæ›²çº¿å›¾", "æŸå¤±ã€å‡†ç¡®ç‡ã€F1ç­‰æŒ‡æ ‡å˜åŒ–")
            curve_filename = visualizer.plot_training_curves(early_stop_info)
            progress_tracker.print_success(f"è®­ç»ƒæ›²çº¿å›¾ç”Ÿæˆå®Œæˆ: {curve_filename}")
            
            progress_tracker.print_substage("ç»˜åˆ¶æ–¹æ³•æ¯”è¾ƒå›¾", "ä¸å…¶ä»–æ–¹æ³•çš„æ€§èƒ½å¯¹æ¯”")
            comparison_filename = visualizer.plot_method_comparison(best_test_f1_score)
            progress_tracker.print_success(f"æ–¹æ³•æ¯”è¾ƒå›¾ç”Ÿæˆå®Œæˆ: {comparison_filename}")
            
            progress_tracker.print_substage("ç”Ÿæˆå®éªŒæŠ¥å‘Š", "è¯¦ç»†çš„è®­ç»ƒå’Œæµ‹è¯•æŠ¥å‘Š")
            report_filename = visualizer.generate_final_report(best_test_f1_score, total_training_time, early_stop_info)
            progress_tracker.print_success(f"å®éªŒæŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_filename}")
            
            progress_tracker.print_success(f"âœ¨ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°å®éªŒç›®å½•: {visualizer.result_dir}")
            progress_tracker.print_success(f"ğŸ†” å®éªŒæ—¶é—´æˆ³: {visualizer.timestamp}")
    
    # æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ
    if world_size > 1:
        cleanup_distributed()
    
    return {
        'train_samples': len(train_dataset),
        'val_samples': len(val_dataset),
        'test_samples': len(test_dataset),
        'epochs': EPOCHES,
        'lr': LR,
        'best_val': best_val_f1_score,
        'best_test': best_test_f1_score,
        'training_time': total_training_time
    }

def main_worker(rank, world_size):
    """å¤šGPUè®­ç»ƒçš„å·¥ä½œè¿›ç¨‹"""
    final_results = train_distributed(rank, world_size)
    return final_results

def main():
    """ä¸»å‡½æ•° - è‡ªåŠ¨æ£€æµ‹å¹¶å¯åŠ¨å•GPUæˆ–å¤šGPUè®­ç»ƒ"""
    print("ğŸš€ C4MMDå¤šæ¨¡æ€éšå–»æ£€æµ‹ - æ™ºèƒ½4-GPUå¹¶è¡Œè®­ç»ƒ")
    print("=" * 80)
    
    # è·å–GPUé…ç½®ï¼ˆä¸»è¿›ç¨‹æ˜¾ç¤ºä¿¡æ¯ï¼‰
    gpu_config = get_gpu_config(show_info=True, rank=0)
    world_size = gpu_config.world_size
    use_multi_gpu = gpu_config.use_multi_gpu
    
    print(f"ğŸ® GPUé…ç½®: {world_size} å¼ GPU")
    print(f"ğŸ“Š è®­ç»ƒé…ç½®: {EPOCHES}è½®æ¬¡, æ‰¹æ¬¡å¤§å°{BATCH_SIZE}/GPU, å­¦ä¹ ç‡{LR}")
    print(f"ğŸ“ˆ æ•°æ®ä½¿ç”¨: {DATA_RATIO*100:.1f}% æ•°æ®é›†")
    print(f"ğŸš€ æ··åˆç²¾åº¦: {'å¯ç”¨' if USE_MIXED_PRECISION else 'ç¦ç”¨'}")
    print(f"â¹ï¸ æ—©åœæœºåˆ¶: ç›‘æ§{args.early_stop_metric}, è€å¿ƒå€¼{args.patience}, é˜ˆå€¼{args.min_delta}")
    print(f"ğŸ•’ æ—¶é—´æˆ³: {datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}")
    print("=" * 80)
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    progress_tracker.print_stage("ç¯å¢ƒå‡†å¤‡é˜¶æ®µ", "åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„")
    
    progress_tracker.print_substage("åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•", "trained_models/")
    os.makedirs('trained_models', exist_ok=True)
    progress_tracker.print_success("æ¨¡å‹ç›®å½•åˆ›å»ºå®Œæˆ")
    
    progress_tracker.print_substage("åˆ›å»ºç»“æœä¿å­˜ç›®å½•", "results/")
    os.makedirs('results', exist_ok=True)
    progress_tracker.print_success("ç»“æœç›®å½•åˆ›å»ºå®Œæˆ")
    
    # å¼€å§‹è®­ç»ƒ
    try:
        if use_multi_gpu:
            # å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ
            progress_tracker.print_success(f"ğŸ® å¯åŠ¨4-GPUå¹¶è¡Œè®­ç»ƒ (NVIDIA DDP + AMP)")
            mp.spawn(main_worker, args=(world_size,), nprocs=world_size, join=True)
            
            # è®­ç»ƒå®Œæˆåï¼Œè¯»å–ç»“æœï¼ˆä»ä¸»è¿›ç¨‹çš„ä¿å­˜æ–‡ä»¶æˆ–è¿”å›å€¼ï¼‰
            print(f"\nğŸ‰ 4-GPUå¹¶è¡Œè®­ç»ƒå®Œæˆ!")
            print(f"ğŸ“Š è®­ç»ƒæ•ˆæœ:")
            print(f"   ğŸš€ 4å€GPUåŠ é€Ÿè®­ç»ƒ")
            print(f"   âš¡ NVIDIAæ··åˆç²¾åº¦ä¼˜åŒ–") 
            print(f"   ğŸ”„ åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ")
            print(f"   â¹ï¸ æ™ºèƒ½æ—©åœæœºåˆ¶")
            print(f"   ğŸ•’ æ—¶é—´æˆ³ç®¡ç†")
            print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"   ğŸ¨ results/training_curves.png - è®­ç»ƒè¿‡ç¨‹æ›²çº¿å›¾")
            print(f"   ğŸ“ˆ results/method_comparison.png - æ–¹æ³•æ€§èƒ½æ¯”è¾ƒå›¾")
            print(f"   ğŸ“„ results/training_report.md - è¯¦ç»†å®éªŒæŠ¥å‘Š")
            print(f"   ğŸ¤– trained_models/C4MMD_ratio{DATA_RATIO:.1f}.pth - è®­ç»ƒå¥½çš„æ¨¡å‹")
            print(f"   ğŸ“‚ results/experiment_YYYYMMDD_HHMMSS/ - å¸¦æ—¶é—´æˆ³çš„å®éªŒç»“æœ")
            print(f"\nâœ¨ æ­å–œï¼æ‚¨å·²æˆåŠŸä½¿ç”¨4-GPUå¹¶è¡Œå®ŒæˆC4MMDå®éªŒ!")
            
        else:
            # å•GPUè®­ç»ƒ
            progress_tracker.print_warning("âš ï¸ æ£€æµ‹åˆ°å•GPUç¯å¢ƒï¼Œä½¿ç”¨å•GPUè®­ç»ƒ")
            final_results = train_single_gpu()
            
            progress_tracker.print_stage("å®éªŒå®Œæˆ", "å•GPUè®­ç»ƒå·²æˆåŠŸå®Œæˆ!")
            
            print(f"\nğŸ‰ C4MMDè®­ç»ƒå’Œå¯è§†åŒ–æµç¨‹åœ†æ»¡å®Œæˆ!")
            print(f"ğŸ“Š æœ€ç»ˆæ€§èƒ½:")
            print(f"   - æµ‹è¯•å‡†ç¡®ç‡: {final_results['best_test']['acc']:.2f}%")
            print(f"   - æµ‹è¯•F1åˆ†æ•°: {final_results['best_test']['f1']:.2f}%")
            print(f"   - æ€»è®­ç»ƒæ—¶é—´: {final_results['training_time']}")
            print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"   ğŸ¨ results/training_curves.png - è®­ç»ƒè¿‡ç¨‹æ›²çº¿å›¾")
            print(f"   ğŸ“ˆ results/method_comparison.png - æ–¹æ³•æ€§èƒ½æ¯”è¾ƒå›¾")
            print(f"   ğŸ“„ results/training_report.md - è¯¦ç»†å®éªŒæŠ¥å‘Š")
            print(f"   ğŸ¤– trained_models/C4MMD_ratio{DATA_RATIO:.1f}.pth - è®­ç»ƒå¥½çš„æ¨¡å‹")
            print(f"   ğŸ“‚ results/experiment_YYYYMMDD_HHMMSS/ - å¸¦æ—¶é—´æˆ³çš„å®éªŒç»“æœ")
            print(f"   â¹ï¸ æ—©åœæœºåˆ¶: {'å·²å¯ç”¨' if args.patience < 50 else 'å·²ç¦ç”¨'}")
            print(f"\nâœ¨ æ­å–œï¼æ‚¨å·²æˆåŠŸå¤ç°C4MMDå®éªŒå¹¶ç”Ÿæˆäº†å®Œæ•´çš„å¯è§†åŒ–ç»“æœ!")
        
    except Exception as e:
        progress_tracker.print_error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        raise e

if __name__ == "__main__":
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ï¼ˆé¿å…CUDAåˆå§‹åŒ–é—®é¢˜ï¼‰
    mp.set_start_method('spawn', force=True)
    main() 