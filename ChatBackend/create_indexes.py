#!/usr/bin/env python3
"""
MongoDB å¤åˆç´¢å¼•åˆ›å»ºè„šæœ¬
ç”¨äºä¼˜åŒ–æ–°é—»ç³»ç»ŸæŸ¥è¯¢æ€§èƒ½ï¼Œæ”¯æŒå®æ—¶çƒ­ç‚¹æ–°é—»æŸ¥è¯¢

ä½¿ç”¨æ–¹æ³•ï¼š
    python create_indexes.py

ç‰¹æ€§ï¼š
- åˆ›å»ºé’ˆå¯¹å®æ—¶æŸ¥è¯¢ä¼˜åŒ–çš„å¤åˆç´¢å¼•
- æ”¯æŒçƒ­åº¦æ’åºå’Œæ—¶é—´è¿‡æ»¤çš„é«˜æ•ˆæŸ¥è¯¢
- åŒ…å«ç´¢å¼•æ€§èƒ½åˆ†æå’ŒéªŒè¯
"""

import pymongo
from datetime import datetime
import time
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def connect_to_mongodb():
    """è¿æ¥åˆ° MongoDB æ•°æ®åº“"""
    try:
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–è¿æ¥ä¿¡æ¯
        mongo_uri = os.getenv('MONGODB_URI', 'mongodb://localhost:27017')
        db_name = os.getenv('MONGODB_DB', 'chatdb')
        
        print(f"ğŸ”— è¿æ¥åˆ° MongoDB: {mongo_uri}")
        client = pymongo.MongoClient(mongo_uri)
        db = client[db_name]
        
        # æµ‹è¯•è¿æ¥
        client.admin.command('ping')
        print(f"âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {db_name}")
        
        return db, client
    except Exception as e:
        print(f"âŒ MongoDB è¿æ¥å¤±è´¥: {str(e)}")
        return None, None

def create_performance_indexes(db):
    """
    åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•
    
    Args:
        db: MongoDB æ•°æ®åº“å®ä¾‹
    """
    print("ğŸ“Š å¼€å§‹åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•...")
    
    indexes_created = 0
    
    try:
        # 1. transformed_news é›†åˆçš„æ ¸å¿ƒç´¢å¼•
        print("\n1ï¸âƒ£ åˆ›å»º transformed_news æ ¸å¿ƒç´¢å¼•...")
        
        # ä¸»è¦æŸ¥è¯¢ç´¢å¼•ï¼šæŒ‰åˆ†ææ—¶é—´ã€å‚ä¸åº¦ã€æ ‡é¢˜æ’åº
        index_name = "idx_analyzed_participants_title"
        db.transformed_news.create_index([
            ("analyzed_at", pymongo.DESCENDING),   # æ—¶é—´è¿‡æ»¤ï¼ˆæœ€æ–°ä¼˜å…ˆï¼‰
            ("participants", pymongo.DESCENDING),  # çƒ­åº¦æ’åº
            ("title", pymongo.ASCENDING)           # æ ‡é¢˜æŸ¥è¯¢å’Œè¿æ¥
        ], name=index_name, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        # è¾…åŠ©æŸ¥è¯¢ç´¢å¼•ï¼šçƒ­åº¦çº§åˆ«è¿‡æ»¤
        index_name = "idx_participants_analyzed"
        db.transformed_news.create_index([
            ("participants", pymongo.DESCENDING),
            ("analyzed_at", pymongo.DESCENDING)
        ], name=index_name, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        # æ ‡é¢˜å”¯ä¸€æŸ¥è¯¢ç´¢å¼•
        index_name = "idx_title_unique"
        db.transformed_news.create_index([
            ("title", pymongo.ASCENDING)
        ], name=index_name, unique=False, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        # 2. news_master é›†åˆçš„çƒ­åº¦æ•°æ®ç´¢å¼•
        print("\n2ï¸âƒ£ åˆ›å»º news_master çƒ­åº¦æ•°æ®ç´¢å¼•...")
        
        # æ—¶é—´æˆ³ç´¢å¼•ï¼ˆè·å–æœ€æ–°æ•°æ®ï¼‰
        index_name = "idx_timestamp_desc"
        db.news_master.create_index([
            ("timestamp", pymongo.DESCENDING),
            ("status", pymongo.ASCENDING)
        ], name=index_name, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        # ç»¼åˆæ’åæ ‡é¢˜ç´¢å¼•ï¼ˆç”¨äº lookup è¿æ¥ï¼‰
        index_name = "idx_comprehensive_title"
        db.news_master.create_index([
            ("comprehensive_ranking.title", pymongo.ASCENDING),
            ("timestamp", pymongo.DESCENDING)
        ], name=index_name, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        # 3. analysis_tasks é˜Ÿåˆ—ä¼˜åŒ–ç´¢å¼•
        print("\n3ï¸âƒ£ åˆ›å»º analysis_tasks é˜Ÿåˆ—ç´¢å¼•...")
        
        # é˜Ÿåˆ—å¤„ç†ç´¢å¼•ï¼šæŒ‰çŠ¶æ€å’Œæ—¶é—´æ’åº
        index_name = "idx_status_queued"
        db.analysis_tasks.create_index([
            ("status", pymongo.ASCENDING),
            ("queued_at", pymongo.ASCENDING)  # FIFO å¤„ç†
        ], name=index_name, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        # æ–°é—»IDå»é‡ç´¢å¼•
        index_name = "idx_news_id_unique"
        db.analysis_tasks.create_index([
            ("news_id", pymongo.ASCENDING)
        ], name=index_name, unique=True, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        # 4. å†å²æ•°æ®æ¸…ç†ç´¢å¼•
        print("\n4ï¸âƒ£ åˆ›å»ºå†å²æ•°æ®ç®¡ç†ç´¢å¼•...")
        
        # æŒ‰æ—¶é—´æ¸…ç†æ—§æ•°æ®çš„ç´¢å¼•
        index_name = "idx_cleanup_timestamp"
        db.analysis_tasks.create_index([
            ("status", pymongo.ASCENDING),
            ("completed_at", pymongo.ASCENDING)
        ], name=index_name, background=True)
        print(f"   âœ… åˆ›å»ºç´¢å¼•: {index_name}")
        indexes_created += 1
        
        print(f"\nğŸ‰ ç´¢å¼•åˆ›å»ºå®Œæˆï¼å…±åˆ›å»º {indexes_created} ä¸ªç´¢å¼•")
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºç´¢å¼•æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def analyze_index_performance(db):
    """
    åˆ†æç´¢å¼•æ€§èƒ½æ•ˆæœ
    
    Args:
        db: MongoDB æ•°æ®åº“å®ä¾‹
    """
    print("\nğŸ“ˆ åˆ†æç´¢å¼•æ€§èƒ½æ•ˆæœ...")
    
    try:
        # 1. æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
        print("\nğŸ” æ£€æŸ¥å·²åˆ›å»ºçš„ç´¢å¼•:")
        
        collections = ['transformed_news', 'news_master', 'analysis_tasks']
        for collection_name in collections:
            collection = db[collection_name]
            indexes = collection.list_indexes()
            
            print(f"\nğŸ“Š {collection_name} é›†åˆç´¢å¼•:")
            for index in indexes:
                index_info = {
                    'name': index['name'],
                    'keys': index['key'],
                    'unique': index.get('unique', False),
                    'background': index.get('background', False)
                }
                print(f"   - {index_info['name']}: {index_info['keys']}")
        
        # 2. æ‰§è¡Œæ€§èƒ½æµ‹è¯•æŸ¥è¯¢
        print("\nâš¡ æ‰§è¡Œæ€§èƒ½æµ‹è¯•æŸ¥è¯¢...")
        
        # æµ‹è¯•å®æ—¶çƒ­ç‚¹æ–°é—»æŸ¥è¯¢
        start_time = time.time()
        
        pipeline = [
            {"$match": {
                "analyzed_at": {"$exists": True},
                "participants": {"$gte": 0.05}
            }},
            {"$sort": {"participants": -1, "analyzed_at": -1}},
            {"$limit": 20},
            {"$project": {
                "title": 1,
                "participants": 1,
                "analyzed_at": 1,
                "_id": 0
            }}
        ]
        
        results = list(db.transformed_news.aggregate(pipeline))
        query_time = time.time() - start_time
        
        print(f"   ğŸ“Š çƒ­ç‚¹æ–°é—»æŸ¥è¯¢: {len(results)} æ¡ç»“æœï¼Œè€—æ—¶ {query_time:.3f}s")
        
        # æµ‹è¯•é˜Ÿåˆ—æŸ¥è¯¢æ€§èƒ½
        start_time = time.time()
        queue_count = db.analysis_tasks.count_documents({"status": "pending"})
        queue_time = time.time() - start_time
        
        print(f"   ğŸ“Š é˜Ÿåˆ—çŠ¶æ€æŸ¥è¯¢: {queue_count} æ¡å¾…å¤„ç†ï¼Œè€—æ—¶ {queue_time:.3f}s")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½åˆ†æå¤±è´¥: {str(e)}")
        return False

def create_mongodb_views(db):
    """
    åˆ›å»º MongoDB è§†å›¾æ¥ç®€åŒ–æŸ¥è¯¢
    
    Args:
        db: MongoDB æ•°æ®åº“å®ä¾‹
    """
    print("\nğŸ” åˆ›å»º MongoDB è§†å›¾...")
    
    try:
        # 1. åˆ›å»ºå®æ—¶çƒ­ç‚¹æ–°é—»è§†å›¾
        view_name = "current_hot_news_view"
        
        # åˆ é™¤å·²å­˜åœ¨çš„è§†å›¾
        try:
            db.drop_collection(view_name)
            print(f"   ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„è§†å›¾: {view_name}")
        except:
            pass
        
        # åˆ›å»ºæ–°è§†å›¾
        pipeline = [
            {"$match": {
                "analyzed_at": {"$gte": "2024-01-01T00:00:00"},  # åŠ¨æ€æ—¶é—´è¿‡æ»¤
                "participants": {"$gte": 0.05}
            }},
            {"$addFields": {
                "heat_level": {
                    "$switch": {
                        "branches": [
                            {"case": {"$gte": ["$participants", 0.8]}, "then": "çˆ†"},
                            {"case": {"$gte": ["$participants", 0.6]}, "then": "çƒ­"},
                            {"case": {"$gte": ["$participants", 0.4]}, "then": "é«˜"},
                            {"case": {"$gte": ["$participants", 0.2]}, "then": "ä¸­"}
                        ],
                        "default": "ä½"
                    }
                }
            }},
            {"$sort": {"participants": -1, "analyzed_at": -1}},
            {"$limit": 50}  # è§†å›¾é™åˆ¶
        ]
        
        db.create_collection(view_name, viewOn="transformed_news", pipeline=pipeline)
        print(f"   âœ… åˆ›å»ºè§†å›¾: {view_name}")
        
        # 2. åˆ›å»ºé˜Ÿåˆ—çŠ¶æ€è§†å›¾
        queue_view_name = "queue_status_view"
        
        try:
            db.drop_collection(queue_view_name)
        except:
            pass
        
        queue_pipeline = [
            {"$group": {
                "_id": "$status",
                "count": {"$sum": 1},
                "latest_queued": {"$max": "$queued_at"}
            }},
            {"$sort": {"count": -1}}
        ]
        
        db.create_collection(queue_view_name, viewOn="analysis_tasks", pipeline=queue_pipeline)
        print(f"   âœ… åˆ›å»ºè§†å›¾: {queue_view_name}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºè§†å›¾å¤±è´¥: {str(e)}")
        return False

def show_optimization_summary():
    """æ˜¾ç¤ºä¼˜åŒ–æ•ˆæœæ€»ç»“"""
    print("""
ğŸ¯ ä¼˜åŒ–æ•ˆæœæ€»ç»“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ç´¢å¼•ä¼˜åŒ–:
   âœ… ä¸»æŸ¥è¯¢ç´¢å¼•: analyzed_at + participants + title
   âœ… çƒ­åº¦æ’åºç´¢å¼•: participants + analyzed_at  
   âœ… è¿æ¥æŸ¥è¯¢ç´¢å¼•: comprehensive_ranking.title + timestamp
   âœ… é˜Ÿåˆ—å¤„ç†ç´¢å¼•: status + queued_at
   âœ… å»é‡ç´¢å¼•: news_id (unique)

ğŸš€ æ€§èƒ½æå‡é¢„æœŸ:
   ğŸ“ˆ æŸ¥è¯¢é€Ÿåº¦: 50-80% æå‡
   ğŸ’¾ å­˜å‚¨æ•ˆç‡: 100% èŠ‚çœï¼ˆæ— å†—ä½™è¡¨ï¼‰
   ğŸ”„ ç»´æŠ¤æˆæœ¬: é›¶ç»´æŠ¤ï¼ˆå®æ—¶è®¡ç®—ï¼‰
   ğŸ¯ æ•°æ®ä¸€è‡´æ€§: å®Œç¾ï¼ˆå•ä¸€æ•°æ®æºï¼‰

ğŸ’¡ ä½¿ç”¨æ–¹æ³•:
   # åŸæ¥çš„æ–¹æ³•
   NewsService.update_current_hot_news()
   
   # æ–°çš„å®æ—¶æ–¹æ³•
   hot_news = NewsService.get_current_hot_news_realtime(limit=20)
   trends = NewsService.get_news_heat_trends("æ–°é—»æ ‡é¢˜", days=7)

ğŸ“‹ ä¸‹ä¸€æ­¥:
   1. æµ‹è¯•æ–°æ–¹æ³•çš„æ€§èƒ½å’Œæ­£ç¡®æ€§
   2. é€æ­¥è¿ç§»å‰ç«¯è°ƒç”¨
   3. åˆ é™¤ update_current_hot_news å’Œ current_hot_news è¡¨
   4. ç§»é™¤ç›¸å…³çš„å®šæ—¶ä»»åŠ¡

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ MongoDB å¤åˆç´¢å¼•ä¼˜åŒ–è„šæœ¬")
    print("=" * 50)
    
    # è¿æ¥æ•°æ®åº“
    db, client = connect_to_mongodb()
    if db is None:
        print("âŒ æ— æ³•è¿æ¥åˆ°æ•°æ®åº“ï¼Œé€€å‡º...")
        return False
    
    try:
        # åˆ›å»ºç´¢å¼•
        if not create_performance_indexes(db):
            print("âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥")
            return False
        
        # åˆ›å»ºè§†å›¾
        if not create_mongodb_views(db):
            print("âš ï¸ è§†å›¾åˆ›å»ºå¤±è´¥ï¼Œä½†ç´¢å¼•å·²æˆåŠŸåˆ›å»º")
        
        # æ€§èƒ½åˆ†æ
        analyze_index_performance(db)
        
        # æ˜¾ç¤ºæ€»ç»“
        show_optimization_summary()
        
        print("ğŸ‰ ä¼˜åŒ–å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return False
        
    finally:
        if client:
            client.close()
            print("ğŸ”— æ•°æ®åº“è¿æ¥å·²å…³é—­")

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
