# 知默系统用户操作手册

## 1. 系统概述

知默系统是一个新闻采集、分析和展示平台，用于实时获取、处理新闻数据并进行公共舆情分析。系统主要包含以下功能模块：

- 新闻自动采集
- 新闻智能处理
- 热点新闻分析
- 趋势分析
- 数据可视化展示
- 数据导出

## 2. 系统部署与配置

### 2.1 环境要求

- Docker 和 Docker Compose
- MongoDB 数据库
- Redis 缓存服务
- Python 3.8+

### 2.2 配置文件说明

系统主要通过 `.env` 文件进行配置，需要包含以下关键配置：

```
SERVER_IP=your_server_ip
SERVER_USER=your_username
REMOTE_DEPLOY_PATH=/path/to/deployment
SSH_KEY_PATH=path/to/your/ssh/key  # 或使用 SERVER_PASSWORD
```

### 2.3 启动和停止服务

```bash
# 启动所有服务
docker-compose -f docker-compose.prod.yml up -d

# 停止所有服务
docker-compose -f docker-compose.prod.yml down

# 仅重启某个服务
docker-compose -f docker-compose.prod.yml restart service_name
```

## 3. 基本操作指南

### 3.1 仪表盘使用

仪表盘位于 `/dashboard` 路径，包含以下组件：

- 热点新闻列表：展示各平台最新热点新闻
- 地理分布图：展示新闻来源地理分布
- 舆情分析卡片：展示公众情感和立场分析
- 词云图：展示热点关键词
- 趋势图：展示舆情变化趋势

### 3.2 数据检索

系统支持多种方式检索数据：

- 关键词搜索
- 时间范围筛选
- 情感倾向筛选
- 来源平台筛选

## 4. 定时任务管理

系统使用 Celery 进行定时任务调度，主要包含以下任务：

| 任务名称 | 频率 | 说明 |
|---------|------|------|
| collect_news | 每小时 | 基础新闻采集 |
| process_news | 每60分钟 | 对采集的新闻进行处理和分析 |
| update_hot_news | 每80分钟 | 更新热点新闻 |
| smart_collect | 每12小时 | 智能新闻采集 |
| analyze_trending | 每24小时 | 趋势分析 |

### 4.1 任务监控

可以通过以下命令查看任务执行状态：

```bash
docker exec -it celery_worker celery -A celery_app inspect active
```

### 4.2 手动触发任务

如需手动触发任务，可以使用以下命令：

```bash
docker exec -it celery_worker celery -A celery_app call tasks.task_name
```

## 5. 数据导出

### 5.1 使用导出脚本

系统提供了 `db_export.sh` 脚本用于导出 MongoDB 数据：

```bash
# 导出所有集合
./db_export.sh

# 导出指定数据库
./db_export.sh --db database_name

# 导出指定集合
./db_export.sh --collection collection_name
```

导出结果将保存在 `./data_exports` 目录下，包含 CSV 格式数据。

### 5.2 注意事项

- `hot_news_processed` 表默认不会被导出
- 数据导出需要确保有足够的磁盘空间
- 大型数据集导出可能需要较长时间

## 6. MongoDB 数据库管理

### 6.1 查看数据库集合

可以通过以下方式查看 MongoDB 中的集合：

```bash
# SSH 连接服务器
ssh 用户名@服务器IP

# 查看数据库中的集合
docker exec mongodb_prod mongosh --quiet --eval "db.getMongo().getDB('zhimo').getCollectionNames()"
```

### 6.2 数据库可视化工具

推荐使用以下工具进行数据库可视化管理：

- MongoDB Compass：通过 SSH 隧道连接
- mongo-express：可以部署为容器服务

## 7. 常见问题和解决方案

### 7.1 任务执行超时

系统为所有 Celery 任务设置了 10 分钟的执行时间限制：
- 硬超时：10 分钟 (600 秒)
- 软超时：9 分钟 (540 秒)

如任务频繁超时，请检查：
- 数据量是否过大
- 网络连接是否稳定
- 服务器资源是否充足

### 7.2 数据不完整

如发现数据不完整，可能的原因：
- 采集任务失败
- 处理任务超时
- 数据源暂时不可用

解决方案：
- 检查任务日志
- 手动触发相应任务
- 调整任务执行频率

## 8. 故障排除

### 8.1 日志查看

```bash
# 查看应用日志
docker-compose -f docker-compose.prod.yml logs app

# 查看 Celery 工作节点日志
docker-compose -f docker-compose.prod.yml logs celery_worker

# 查看 Celery 调度器日志
docker-compose -f docker-compose.prod.yml logs celery_beat
```

### 8.2 系统重启

如系统出现异常，可尝试按以下顺序重启服务：

```bash
# 重启 MongoDB 和 Redis
docker-compose -f docker-compose.prod.yml restart mongodb_prod redis

# 重启 Celery 服务
docker-compose -f docker-compose.prod.yml restart celery_worker celery_beat

# 重启主应用
docker-compose -f docker-compose.prod.yml restart app
```

## 9. 联系与支持

如有更多问题或需要技术支持，请联系系统管理员或开发团队。

---

*文档最后更新日期：2023年12月1日* 